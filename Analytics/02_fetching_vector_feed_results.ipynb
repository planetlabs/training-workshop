{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Planet Analytics API Tutorial\n",
    "\n",
    "# Getting Vector Analytic Feed Results\n",
    "This notebook shows how to paginate through Planet Analytic Feed Results for an existing Change or Object Deteciton analytics [Subscription](https://developers.planet.com/docs/analytics/#subscriptions) to construct a combined [geojson](https://geojson.org/) feature collection that can be imported into geospatial analysis tools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup \n",
    "To use this notebook, you need an api key for a Planet account with access to the Analytics API.\n",
    "#### API Key and Test Connection\n",
    "Set `API_KEY` below if it is not already in your notebook as an environment variable.\n",
    "See the [Analytics API Docs](https://developers.planet.com/docs/analytics/) for more details on authentication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "# construct auth tuple for use in the requests library\n",
    "API_KEY = os.environ.get('PL_API_KEY')\n",
    "BASIC_AUTH = (API_KEY, '')\n",
    "BASE_URL = \"https://api.planet.com/analytics/\"\n",
    "\n",
    "subscriptions_list_url = BASE_URL + 'subscriptions' + '?â€šlimit=1000'\n",
    "resp = requests.get(subscriptions_list_url, auth=BASIC_AUTH)\n",
    "if resp.status_code == 200:\n",
    "    print('Yay, you can access the Analytics API')\n",
    "    subscriptions = resp.json()['data']\n",
    "    print('Available subscriptions:', len(subscriptions))\n",
    "else:\n",
    "    print('Something is wrong:', resp.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specify Analytics Subscription of Interest\n",
    "Below we will list your available subscription ids and some metadata in a dataframe and then select a subscription of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 1000\n",
    "df = pd.DataFrame(subscriptions[:10])\n",
    "df['start'] = pd.to_datetime(df['startTime']).dt.date\n",
    "df['end'] = pd.to_datetime(df['endTime']).dt.date\n",
    "df[['id', 'title', 'description', 'start', 'end']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick a subscription from which to pull results, copy its ID and replace below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This example ID is for a subscription of building change detections in Kabul\n",
    "# You can replace this ID with your own subscription ID\n",
    "SUBSCRIPTION_ID = '9b80bb51-ee89-48f2-a03c-c59398444915'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting subscription results\n",
    "In this section, we will make sure that we can get data from the subscription of interest by fetching the latest page of results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the url for the subscription's results collection\n",
    "subscription_results_url = BASE_URL + 'collections/' + SUBSCRIPTION_ID + '/items'\n",
    "print(\"Request URL: {}\".format(subscription_results_url))\n",
    "\n",
    "# Get subscription results collection, print the first one\n",
    "resp = requests.get(subscription_results_url, auth=BASIC_AUTH)\n",
    "if resp.status_code == 200:\n",
    "    print('Yay, you can access analytic feed results!')\n",
    "    subscription_results = resp.json()\n",
    "    #Printing the ID from the first subscription\n",
    "    print(json.dumps(subscription_results['features'][0]['id'], sort_keys=True, indent=2))\n",
    "else:\n",
    "    print('Something is wrong:', resp.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pagination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The response json above will only include the most recent 250 detections by default. For subscriptions with many results, you can page through "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(subscription_results['features']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More results can be fetched by following the `next` link. Let's look at the links section of the response:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription_results['links']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get more results, we will want the link with a `rel` of `next`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_link(results_json):\n",
    "    \"\"\"Given a response json from one page of subscription results, get the url for the next page of results.\"\"\"\n",
    "    for link in results_json['links']:\n",
    "        if link['rel'] == 'next':\n",
    "            return link['href']\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_link = get_next_link(subscription_results)\n",
    "print('next page url: {}'.format(next_link))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the result above is `None`, it means your subscription has less than 250 results and you don't need to run the following cell. If there are more than 250 detections, the return will be a URL. Using this url, we can fetch the next page of results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_results = requests.get(next_link, auth=BASIC_AUTH).json()\n",
    "print(json.dumps(next_results['features'][0]['id'], sort_keys=True, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregating results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each page of results comes as one feature collection. We can combine the features from different pages of results into one big feature collection. Below we will page through all results in the subscription from the past 12 months and make a combined feature collection.\n",
    "\n",
    "Results in the API are ordered by a `created` timestamp. This corresponds the time that the feature was published to a Feed and does not necessarily match the `observed` timestamp in the feature's properties, which corresponds to when the source imagery for a feature was collected.\n",
    "\n",
    "This means that if your subscritpion was created with backfill you will have a ton of detections on the same day. In this case you might want to add an additional filter by date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_feature = subscription_results['features'][0]\n",
    "creation_datestring = latest_feature['created']\n",
    "print('latest feature creation date:', creation_datestring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil.parser import parse\n",
    "# this date string can be parsed as a datetime and converted to a date\n",
    "latest_date = parse(creation_datestring).date()\n",
    "latest_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "min_date = latest_date - timedelta(days=365)\n",
    "print('Aggregate all detections from after this date:', min_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have a ton of detections this might run for a long time. Think about setting a max number of detections, note that they will be increasing by increments of 250."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_collection = {'type': 'FeatureCollection', 'features': []}\n",
    "next_link = subscription_results_url\n",
    "max_number_detections = 2000\n",
    "\n",
    "while next_link and len(feature_collection['features']) < max_number_detections:\n",
    "    results = requests.get(next_link, auth=BASIC_AUTH).json()\n",
    "    next_features = results['features']\n",
    "    if next_features:\n",
    "        latest_feature_creation = parse(next_features[0]['created']).date()\n",
    "        earliest_feature_creation = parse(next_features[-1]['created']).date()\n",
    "        print('Fetched {} features fetched ({}, {})'.format(\n",
    "            len(next_features), earliest_feature_creation, latest_feature_creation))\n",
    "        feature_collection['features'].extend(next_features)\n",
    "        next_link = get_next_link(results)\n",
    "    else:\n",
    "        next_link = None\n",
    "\n",
    "print('Total features: {}'.format(len(feature_collection['features'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Results\n",
    "We can now save the combined geojson feature collection to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import FileLink, FileLinks\n",
    "os.makedirs('data', exist_ok=True)\n",
    "filename = 'data/combined_collection_{}.geojson'.format(SUBSCRIPTION_ID)\n",
    "with open(filename, 'w') as file:\n",
    "    json.dump(feature_collection, file)\n",
    "\n",
    "FileLink(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we can save the detections in separated files according to the `observed` dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter unique Observed datas in the Feature Collection\n",
    "observed_dates = list(sorted(set([i['properties']['observed'] for i in feature_collection['features']])))\n",
    "\n",
    "# Save all detections per month\n",
    "for date in observed_dates:\n",
    "    filename = 'data/collection_{}_{}.geojson'.format(SUBSCRIPTION_ID, date.split(\"T\")[0])\n",
    "    with open(filename, 'w') as file:\n",
    "        monthly_features = [i for i in feature_collection['features'] if i['properties']['observed'] == date]\n",
    "        fc = {'type': 'FeatureCollection', 'features': monthly_features}\n",
    "        json.dump(fc, file)\n",
    "    print(filename)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After downloading the aggregated geojson file with the file link above, try importing the data into a geojson-compatible tool for visualization and exploration:\n",
    "- [geojson.io](http://geojson.io/)\n",
    "- [kepler gl](https://kepler.gl/demo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The saved combined geojson file can also be used to make a geopandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpd.read_file(filename)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
